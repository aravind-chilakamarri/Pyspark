{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN6c81pio/adKtrj7y6Si0D",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aravind-chilakamarri/Pyspark/blob/main/Pyspark_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Next:\n",
        "1. Dropping Columns\n",
        "2. Dropping Rows\n",
        "3. Various Parameters in Dropping functionalities\n",
        "4. Handling Missing Values by Mean, Median and Mode\n"
      ],
      "metadata": {
        "id": "du_afvrL-IfE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark"
      ],
      "metadata": {
        "id": "JCopQ9npU2o5",
        "outputId": "8a76b7d8-0247-4762-8569-50ff63161293",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.0.tar.gz (316.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.9/316.9 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.0-py2.py3-none-any.whl size=317425344 sha256=3e894c5a6e6028ed129c8a5548fb388fabf1cc04e578e4c9293d7765e25c61a1\n",
            "  Stored in directory: /root/.cache/pip/wheels/41/4e/10/c2cf2467f71c678cfc8a6b9ac9241e5e44a01940da8fbb17fc\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "_JiXHzBr8y-K"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession.builder.appName('Practise 3').getOrCreate()"
      ],
      "metadata": {
        "id": "R4ibqyr7_cbf"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd_df = pd.read_csv('https://raw.githubusercontent.com/aravind-chilakamarri/Pyspark/main/datasets/test2.csv')\n",
        "df_pyspark = spark.createDataFrame(pd_df)"
      ],
      "metadata": {
        "id": "MfU44jd7_kjg"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jn5nFnSpAmcB",
        "outputId": "bcf679f4-960b-4e12-c083-3e7219b14834"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+----+----------+--------+\n",
            "|name| age|experience|  salary|\n",
            "+----+----+----------+--------+\n",
            "|   a|27.0|       2.0|100000.0|\n",
            "|   b|28.0|       3.0|200000.0|\n",
            "|   c|40.0|       7.0|340000.0|\n",
            "|   d| NaN|       4.0|150000.0|\n",
            "|   e| NaN|       NaN|180000.0|\n",
            "|   f|29.0|       6.0|175600.0|\n",
            "| NaN|23.0|       NaN|120000.0|\n",
            "| NaN|25.0|       5.0|170000.0|\n",
            "|   g|27.0|       NaN|     NaN|\n",
            "|   h|28.0|       NaN| 19000.0|\n",
            "+----+----+----------+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Drop the columns\n",
        "df_pyspark.drop('name').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bmQmK3KnAqCe",
        "outputId": "5f9cf989-ebcb-435f-8e57-e86a38fdf257"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+----------+--------+\n",
            "| age|experience|  salary|\n",
            "+----+----------+--------+\n",
            "|27.0|       2.0|100000.0|\n",
            "|28.0|       3.0|200000.0|\n",
            "|40.0|       7.0|340000.0|\n",
            "| NaN|       4.0|150000.0|\n",
            "| NaN|       NaN|180000.0|\n",
            "|29.0|       6.0|175600.0|\n",
            "|23.0|       NaN|120000.0|\n",
            "|25.0|       5.0|170000.0|\n",
            "|27.0|       NaN|     NaN|\n",
            "|28.0|       NaN| 19000.0|\n",
            "+----+----------+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KYxUEiJKAwyo",
        "outputId": "4dda333f-02ab-4e25-ebd3-cfb6c678feaf"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+----+----------+--------+\n",
            "|name| age|experience|  salary|\n",
            "+----+----+----------+--------+\n",
            "|   a|27.0|       2.0|100000.0|\n",
            "|   b|28.0|       3.0|200000.0|\n",
            "|   c|40.0|       7.0|340000.0|\n",
            "|   d| NaN|       4.0|150000.0|\n",
            "|   e| NaN|       NaN|180000.0|\n",
            "|   f|29.0|       6.0|175600.0|\n",
            "| NaN|23.0|       NaN|120000.0|\n",
            "| NaN|25.0|       5.0|170000.0|\n",
            "|   g|27.0|       NaN|     NaN|\n",
            "|   h|28.0|       NaN| 19000.0|\n",
            "+----+----+----------+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop columns using null values\n",
        "# this drop wherever null values are present\n",
        "\n",
        "df_pyspark.na.drop().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rApwEy9TA3e-",
        "outputId": "c1743959-f992-46b7-d3f3-7c4b7405f05f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+----+----------+--------+\n",
            "|name| age|experience|  salary|\n",
            "+----+----+----------+--------+\n",
            "|   a|27.0|       2.0|100000.0|\n",
            "|   b|28.0|       3.0|200000.0|\n",
            "|   c|40.0|       7.0|340000.0|\n",
            "|   f|29.0|       6.0|175600.0|\n",
            "| NaN|25.0|       5.0|170000.0|\n",
            "+----+----+----------+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#how, any, threshold\n",
        "\n",
        "#any == how\n",
        "\n",
        "df_pyspark.na.drop(how='all').show() #if a row with all values as null then it will get dropped"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0WIBZIwzBAP9",
        "outputId": "335153fc-39c5-4eb4-cfac-c573dae317ec"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+----+----------+--------+\n",
            "|name| age|experience|  salary|\n",
            "+----+----+----------+--------+\n",
            "|   a|27.0|       2.0|100000.0|\n",
            "|   b|28.0|       3.0|200000.0|\n",
            "|   c|40.0|       7.0|340000.0|\n",
            "|   d| NaN|       4.0|150000.0|\n",
            "|   e| NaN|       NaN|180000.0|\n",
            "|   f|29.0|       6.0|175600.0|\n",
            "| NaN|23.0|       NaN|120000.0|\n",
            "| NaN|25.0|       5.0|170000.0|\n",
            "|   g|27.0|       NaN|     NaN|\n",
            "|   h|28.0|       NaN| 19000.0|\n",
            "+----+----+----------+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.na.drop(how='any').show() # default and if any column has null the drop complete row"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w713EdVTBXtP",
        "outputId": "9b02cec3-176c-4f8a-9eb8-4589f34c7e88"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+----+----------+--------+\n",
            "|name| age|experience|  salary|\n",
            "+----+----+----------+--------+\n",
            "|   a|27.0|       2.0|100000.0|\n",
            "|   b|28.0|       3.0|200000.0|\n",
            "|   c|40.0|       7.0|340000.0|\n",
            "|   f|29.0|       6.0|175600.0|\n",
            "| NaN|25.0|       5.0|170000.0|\n",
            "+----+----+----------+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.na.drop(thresh=2).show() # if there are any 2 values then keep the row otherwise delete"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tzsiU6gABeyy",
        "outputId": "91ec82f0-3e98-4b95-da0e-8a132a9dbff7"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+----+----------+--------+\n",
            "|name| age|experience|  salary|\n",
            "+----+----+----------+--------+\n",
            "|   a|27.0|       2.0|100000.0|\n",
            "|   b|28.0|       3.0|200000.0|\n",
            "|   c|40.0|       7.0|340000.0|\n",
            "|   d| NaN|       4.0|150000.0|\n",
            "|   e| NaN|       NaN|180000.0|\n",
            "|   f|29.0|       6.0|175600.0|\n",
            "| NaN|23.0|       NaN|120000.0|\n",
            "| NaN|25.0|       5.0|170000.0|\n",
            "|   g|27.0|       NaN|     NaN|\n",
            "|   h|28.0|       NaN| 19000.0|\n",
            "+----+----+----------+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#subset\n",
        "\n",
        "df_pyspark.na.drop(how = \"any\", subset = ['experience']).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ugNNxs0WB1iA",
        "outputId": "ed483c14-627d-4406-9ce0-a7b24329e83f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+----+----------+--------+\n",
            "|name| age|experience|  salary|\n",
            "+----+----+----------+--------+\n",
            "|   a|27.0|       2.0|100000.0|\n",
            "|   b|28.0|       3.0|200000.0|\n",
            "|   c|40.0|       7.0|340000.0|\n",
            "|   d| NaN|       4.0|150000.0|\n",
            "|   f|29.0|       6.0|175600.0|\n",
            "| NaN|25.0|       5.0|170000.0|\n",
            "+----+----+----------+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Filling the Missing values\n",
        "\n",
        "df_pyspark.na.fill('Missing values',['name']).show() #ignoring non-string columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E_X3DsQ6CTjr",
        "outputId": "e91a9835-77f4-4fc8-a15f-e839b6a1a0ec"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+----+----------+--------+\n",
            "|name| age|experience|  salary|\n",
            "+----+----+----------+--------+\n",
            "|   a|27.0|       2.0|100000.0|\n",
            "|   b|28.0|       3.0|200000.0|\n",
            "|   c|40.0|       7.0|340000.0|\n",
            "|   d| NaN|       4.0|150000.0|\n",
            "|   e| NaN|       NaN|180000.0|\n",
            "|   f|29.0|       6.0|175600.0|\n",
            "| NaN|23.0|       NaN|120000.0|\n",
            "| NaN|25.0|       5.0|170000.0|\n",
            "|   g|27.0|       NaN|     NaN|\n",
            "|   h|28.0|       NaN| 19000.0|\n",
            "+----+----+----------+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# impute the values in the place of NULLS\n",
        "\n",
        "from pyspark.ml.feature import Imputer\n",
        "\n",
        "imputer = Imputer(\n",
        "          inputCols = ['age','experience','salary'],\n",
        "          outputCols = [\"{}_imputed\".format(c) for c in ['age','experience','salary']]\n",
        ").setStrategy('mean')\n"
      ],
      "metadata": {
        "id": "DFsz0oaQClLE"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add imputation cols to df_pyspark\n",
        "\n",
        "imputer.fit(df_pyspark).transform(df_pyspark).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5rNFMWQwEMkT",
        "outputId": "a3e1326f-e636-47fb-aec3-7c093b851b50"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+----+----------+--------+-----------+------------------+------------------+\n",
            "|name| age|experience|  salary|age_imputed|experience_imputed|    salary_imputed|\n",
            "+----+----+----------+--------+-----------+------------------+------------------+\n",
            "|   a|27.0|       2.0|100000.0|       27.0|               2.0|          100000.0|\n",
            "|   b|28.0|       3.0|200000.0|       28.0|               3.0|          200000.0|\n",
            "|   c|40.0|       7.0|340000.0|       40.0|               7.0|          340000.0|\n",
            "|   d| NaN|       4.0|150000.0|     28.375|               4.0|          150000.0|\n",
            "|   e| NaN|       NaN|180000.0|     28.375|               4.5|          180000.0|\n",
            "|   f|29.0|       6.0|175600.0|       29.0|               6.0|          175600.0|\n",
            "| NaN|23.0|       NaN|120000.0|       23.0|               4.5|          120000.0|\n",
            "| NaN|25.0|       5.0|170000.0|       25.0|               5.0|          170000.0|\n",
            "|   g|27.0|       NaN|     NaN|       27.0|               4.5|161622.22222222222|\n",
            "|   h|28.0|       NaN| 19000.0|       28.0|               4.5|           19000.0|\n",
            "+----+----+----------+--------+-----------+------------------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "w95MqxW4VxBv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}